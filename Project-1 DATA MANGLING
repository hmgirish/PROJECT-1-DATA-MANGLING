import pandas as pd import
numpy as np import
matplotlib.pyplot as plt
%matplotlib inline
df =
pd.read_csv('https://raw.githubusercontent.com/jackiekazil/data-wrangling/master/dat
a/chp3/data-text.csv') df.head(2)
df1 =
pd.read_csv('https://raw.githubusercontent.com/kjam/data-wrangling-pycon/master/d
ata/berlin_weather_oldest.csv') df1.head(2)

Solution:

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
%matplotlib inline
df = pd.read_csv('''https://raw.githubusercontent.com/jackiekazil/data-wrangling/master/data/chp3/data-text.csv''') 
df.head(2)
df1 = pd.read_csv('''https://raw.githubusercontent.com/kjam/data-wrangling-pycon/master/data/berlin_weather_oldest.csv''') 
df1.head(2)

1. Get the Metadata from the above files.

Solution:

df.info()
df1.info()

2. Get the row names from the above files.

Solution:

df.index.values
df1.index.values

3. Change the column name from any of the above file.

Solution:

df.columns = ['Indicator_ID', 'PUBLISH STATES', 'Year', 'WHO region',
       'World Bank income group', 'Country', 'Sex', 'Display Value', 'Numeric',
       'Low', 'High', 'Comments']
df.head(2)

4. Change the column name from any of the above file and store the changes made
permanently.

Solution:

df.rename(columns={'Indicator': 'Indicator_ID'}, inplace = True)
df.head(2)

5. Change the names of multiple columns.

Solution:

df.rename(columns={'PUBLISH STATES': 'Publication Status', 'WHO region': 'WHO Region'}, inplace = True)
df.head(2)

6. Arrange values of a particular column in ascending order.

Solution:

df.sort_values(by=['Year'])

7. Arrange multiple column values in ascending order.

Solution:

df.sort_values(by=['Country', 'Year'])

8. Make country as the first column of the dataframe.

Solution:

cols = df.columns.tolist()
n = int(cols.index('Country'))
cols = [cols[n]] + cols[:n] + cols[n+1:]
df = df[cols]
df.head()

9. Get the column array using a variable

Solution:

df['WHO Region'].values

10. Get the subset rows 11, 24, 37

Solution:

df.loc[df.index[[11,24,37]]]

11. Get the subset rows excluding 5, 12, 23, and 56

Solution:

df.drop([5,12,23,56])

-------------------------------------

Load datasets from CSV
users = pd.read_csv('https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/users.csv' )
sessions = pd.read_csv('https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/sessions.csv' )
products = pd.read_csv('https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/products.csv' )
transactions = pd.read_csv('https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/transactions.csv')
users.head() sessions.head() transactions.head()

Solution:

users = pd.read_csv('https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/users.csv')
sessions = pd.read_csv('https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/sessions.csv')
products = pd.read_csv('https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/products.csv')
transactions = pd.read_csv('https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/transactions.csv')

# Convert date columns to Date type

users['Registered'] = pd.to_datetime(users.Registered)
users['Cancelled'] = pd.to_datetime(users.Cancelled)
transactions['TransactionDate'] = pd.to_datetime(transactions.TransactionDate)
sessions['SessionDate'] = pd.to_datetime(sessions.SessionDate)

12. Join users to transactions, keeping all rows from transactions and only matching rows
from users (left join)

Solution:

transactions.merge(users, how='left', on='UserID')

13. Which transactions have a UserID not in users?

Solution:

transactions[~transactions['UserID'].isin(users['UserID'])]

14. Join users to transactions, keeping only rows from transactions and users that match via UserID (inner join)

Solution:

transactions.merge(users, how='inner', on='UserID')

15. Join users to transactions, displaying all matching rows AND all non-matching rows (full outer join)

Solution:

transactions.merge(users, how='outer', on='UserID')

16. Determine which sessions occurred on the same day each user registered

Solution:

pd.merge(left=users, right=sessions, how='inner', left_on=['UserID', 'Registered'], right_on=['UserID', 'SessionDate'])

17. Build a dataset with every possible (UserID, ProductID) pair (cross join)

Solution:

df1 = pd.DataFrame({'key': np.repeat(1, users.shape[0]), 'UserID': users.UserID})
df2 = pd.DataFrame({'key': np.repeat(1, products.shape[0]), 'ProductID': products.ProductID})
pd.merge(df1, df2,on='key')[['UserID', 'ProductID']]

18. Determine how much quantity of each product was purchased by each user

Solution:

user_products = pd.merge(df1, df2,on='key')[['UserID', 'ProductID']]
pd.merge(user_products, transactions, how='left', on=['UserID', 'ProductID']).groupby(['UserID', 'ProductID']).apply(lambda x: pd.Series(dict(
    Quantity=x.Quantity.sum()))).reset_index().fillna(0)
    
19. For each user, get each possible pair of pair transactions (TransactionID1, TransacationID2)

Solution:

pd.merge(transactions, transactions, on='UserID')

20. Join each user to his/her first occuring transaction in the transactions table

Solution:

pd.merge(users, transactions.groupby('UserID').first().reset_index(), how='left', on='UserID')
